---
title: 简单爬虫
date: 2018-09-29 01:17:32
updated: 2018-9-29 23:19
tags: [Requests, 爬虫]
categories: Python
declare: true
toc: true
keywords: "crawler, request, python"
---
# Requests库入门

>- [http://www.python-requests.org/en/master/](http://www.python-requests.org/en/master/)
>- [requests](http://www.python-requests.org/en/master/)

## Requests库的7个主要方法

|方法|说明|
|:--:|:--:|
|requests.request()|构造一个请求，支撑以下各方法的基本方法|
|requests.get()|获取HTML网面的方法|
|requests.head()|获取HTML网页头部信息的方法|
|requests.post()|向HTML网页提交POST请求的方法|
|requests.put()|向HTML页面提交PUT请求的方法|
|requests.patch()|向HTML网页提交局部修改请求|
|requests.delete()|向HTML网页提交删除请求|

<!-- more -->

## Requests库的get()方法

`requests.get(url,params=None,**kwargs)`
1. url：拟获取页面的url链接
2. params：url中的额外参数，字典或字节流格式，可选
3. **kwargs：12个控制访问的参数


 `r = requests.get(url)`
* r为一个包含服务器资源的Response对象(即为requests.get()返回内容)
* get()方法和url构造了一个向服务器请求资源的Request对象



### Response对象

Response对象包含服务器反回的所有信息，也包含请求的Request信息

##### Response对象的属性

| 属性 | 说明 |
| :--: | :--: |
|r.stats_code|HTTP请求的返回状态，200表示连接成功|
|r.txt|HTTP响应的字符串形式|
|r.encoding|从HTTP header中猜测的响应方式的内容编码|
|r.apparent_enconding|从内容中分析出的响应内容编码方式（备选编码方式）|
|r.content|HTTP响应内容编码的二进制形式|

1. r.encoding:如果charset不存在，则默认编码为ISO-8859-1，r.text根据r.encoding显示网页内容
2. r.apparent_encoding：根据网页内容分析出的编码方式

<font size="3" color="green">理解Response异常</font>
`r.raise_for_status()`如果不是200，产生异常requests.HTTPError异常
```
r.raise_for_status()在方法内部判断r.statu_code是否等于200，不需要增加额外的if语句，该语句便于try-except进行异常处理
```
### Requests库的异常
|异常|说明|
|:--:|:--:|
|requests.ConnectonError|网路连接错误异常|
|requests.HTTPError|HTTP错误异常|
|requests.URLRequire|URL缺失异常|
|requests.TooManyRedirects|超过最大重定向次数，产生重定向异常|
|requests.ConnectTimeout|连接远程服务器异常|
|requests.Timeout|请求URL超时，产生超时异常|


## python爬取网页代码通用框架

```python
import requests
#import time

def getHTMLText(url):
    try:
        r = requests.get(url,timeout = 30)
        r.raise_for_status()#如果状态不是200，产生HTTPError异常
        #print(r.status_code)
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return "产生异常"

if __name__ == '__main__':
    url = "http://www.baidu.com"
    print(getHTMLText(url))
```

## Requests库的request()方法

	requests.request(method, url, **kwargs)
* method: 请求方式，对应get/put/delete等7种
* url:拟获取页面的url链接
* **kwargs: 控制访问的参数

### kwargs:控制访问参数，（可选）

```描述
params：字典或字节序列，作为参数增加到URL中
data：字典、字节序列或文章对象，作为Request的内容
json：Json格式的数据
headers：HTTP定制头
cookies：字典或CookieJar，Request中的cookie
auth：元组，支持HTTP认证功能
file：字典类型，传输文件
timeout：设置超时时间，单位为秒
proxies：字典类型，设定访问代理服务器，可以增加登录认证
allow_redirects：True/False，默认为True，重定向开关
strem：True/False，默认为True，获取页面立即下载开关
verify：True/False，默认为True,认证SSl证书开关
cert：本地SSL证书
```

---